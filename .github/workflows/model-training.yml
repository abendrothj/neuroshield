name: NeuraShield Model Training Pipeline

on:
  # Run on a schedule (weekly on Sunday)
  schedule:
    - cron: '0 0 * * 0'
  
  # Run when manually triggered
  workflow_dispatch:
    inputs:
      dataset:
        description: 'Dataset to use for training'
        required: true
        default: 'latest'
      epochs:
        description: 'Number of epochs to train'
        required: true
        default: '100'
      batch_size:
        description: 'Batch size for training'
        required: true
        default: '64'

jobs:
  train-and-evaluate:
    runs-on: ubuntu-latest
    
    # Environment with GPU
    environment: gpu-training
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          pip install -r ai_models/requirements.txt
          
      - name: Download latest datasets
        run: |
          mkdir -p ai_models/datasets/training
          
          # Download datasets from secure storage
          # This is a placeholder, replace with actual download logic
          echo "Downloading latest datasets..."
          
      - name: Train model
        run: |
          cd ai_models
          
          # Configure training parameters
          export DATASET="${{ github.event.inputs.dataset || 'latest' }}"
          export EPOCHS="${{ github.event.inputs.epochs || '100' }}"
          export BATCH_SIZE="${{ github.event.inputs.batch_size || '64' }}"
          
          # Run training script
          python train_neurashield.py \
            --dataset "$DATASET" \
            --epochs "$EPOCHS" \
            --batch_size "$BATCH_SIZE" \
            --output_dir "./models/training_$(date +%Y%m%d_%H%M%S)"
        
      - name: Evaluate model
        run: |
          cd ai_models
          
          # Find the latest trained model
          LATEST_MODEL=$(find ./models -name "training_*" -type d | sort | tail -n 1)
          
          # Run evaluation script
          python analyze_model.py \
            --model_path "$LATEST_MODEL" \
            --test_split 0.2 \
            --output_dir "$LATEST_MODEL/evaluation"
            
          # Store evaluation metrics
          cat "$LATEST_MODEL/evaluation/metrics.json"
      
      - name: Run deployment decision
        id: deploy
        run: |
          cd ai_models
          
          # Find the latest trained model
          LATEST_MODEL=$(find ./models -name "training_*" -type d | sort | tail -n 1)
          
          # Read the evaluation metrics
          METRICS_FILE="$LATEST_MODEL/evaluation/metrics.json"
          
          # Extract the accuracy from metrics
          ACCURACY=$(jq '.accuracy' "$METRICS_FILE")
          
          # Check if the model beats the threshold
          THRESHOLD=0.95
          if (( $(echo "$ACCURACY > $THRESHOLD" | bc -l) )); then
            echo "Model accuracy $ACCURACY exceeds threshold $THRESHOLD"
            echo "deploy=true" >> $GITHUB_OUTPUT
            echo "model_path=$LATEST_MODEL" >> $GITHUB_OUTPUT
          else
            echo "Model accuracy $ACCURACY is below threshold $THRESHOLD"
            echo "deploy=false" >> $GITHUB_OUTPUT
          fi
      
      - name: Deploy model
        if: steps.deploy.outputs.deploy == 'true'
        run: |
          cd ai_models
          
          # Deploy the model
          python deploy_model.py \
            --model_path ${{ steps.deploy.outputs.model_path }} \
            --description "Auto-trained model from CI/CD pipeline"
          
          # Restart AI service to use new model
          # This would depend on your deployment strategy

      - name: Upload artifacts
        uses: actions/upload-artifact@v3
        with:
          name: model-artifacts
          path: |
            ai_models/models/training_*/evaluation
            ai_models/models/training_*/metadata.json
            ai_models/models/threat_detection_latest
            ai_models/training_logs
          
      - name: Notify team
        if: always()
        run: |
          # Send notification about the training run
          # This is a placeholder, replace with actual notification logic
          echo "Sending notification about training run"
          
          if [[ "${{ steps.deploy.outputs.deploy }}" == "true" ]]; then
            echo "New model deployed successfully!"
          else
            echo "Model training completed but did not meet deployment criteria."
          fi 